{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "971bc53a-1e07-45c4-a813-f26d0c153c6d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarxiv in /usr/local/lib/python3.9/site-packages (1.0.3.1)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/site-packages (from pyarxiv) (2.8.2)\n",
      "Requirement already satisfied: feedparser in /usr/local/lib/python3.9/site-packages (from pyarxiv) (6.0.10)\n",
      "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.9/site-packages (from feedparser->pyarxiv) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil->pyarxiv) (1.16.0)\n",
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.1.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.2.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\n",
      "Requirement already satisfied: pybtex in /usr/local/lib/python3.9/site-packages (0.24.0)\n",
      "Requirement already satisfied: PyYAML>=3.01 in /usr/local/lib/python3.9/site-packages (from pybtex) (5.4.1)\n",
      "Requirement already satisfied: latexcodec>=1.0.4 in /usr/local/lib/python3.9/site-packages (from pybtex) (2.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.9/site-packages (from pybtex) (1.16.0)\n",
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.1.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.2.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\n",
      "Requirement already satisfied: dropbox in /usr/local/lib/python3.9/site-packages (11.36.2)\n",
      "Requirement already satisfied: requests>=2.16.2 in /usr/local/lib/python3.9/site-packages (from dropbox) (2.29.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/site-packages (from dropbox) (1.16.0)\n",
      "Requirement already satisfied: stone>=2 in /usr/local/lib/python3.9/site-packages (from dropbox) (3.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests>=2.16.2->dropbox) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests>=2.16.2->dropbox) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests>=2.16.2->dropbox) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests>=2.16.2->dropbox) (2022.12.7)\n",
      "Requirement already satisfied: ply>=3.4 in /usr/local/lib/python3.9/site-packages (from stone>=2->dropbox) (3.11)\n",
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.1.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.2.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/site-packages (4.65.0)\n",
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.1.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.2.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\n",
      "Requirement already satisfied: pycolors2 in /usr/local/lib/python3.9/site-packages (0.0.4)\n",
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.1.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.2.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\n",
      "Requirement already satisfied: pdf2image in /usr/local/lib/python3.9/site-packages (1.16.3)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.9/site-packages (from pdf2image) (9.5.0)\n",
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.1.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.2.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\n",
      "Requirement already satisfied: Unidecode in /usr/local/lib/python3.9/site-packages (1.3.6)\n",
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.1.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.2.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pyarxiv\n",
    "!pip3 install pybtex\n",
    "!pip3 install dropbox\n",
    "!pip3 install tqdm\n",
    "!pip3 install pycolors2\n",
    "!pip3 install pdf2image\n",
    "!pip3 install Unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce4d4a1a-89e6-4f70-bc4e-77cf301d9191",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from bib_handling_code.processbib import read_bibfile\n",
    "from bib_handling_code.processbib import save_to_file\n",
    "import requests\n",
    "import pandas as pd \n",
    "from get_biblatex import GetBiblatex\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea4d1227-a735-47e5-975e-ae4cb703a691",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path_diag_bib = os.path.join('script_data/', 'diag_ss.bib')\n",
    "diag_bib_raw = read_bibfile(None, path_diag_bib) # I changed the code in such a way that IF I give a second argument, it uses the second argument as a full path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "70e5d466-32a0-4522-8675-8ce625b4cfcc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "staff_id_dict = {'Bram van Ginneken': [8038506, 123637526],\n",
    "'Francesco Ciompi': [143613202],\n",
    "'Alessa Hering': [153744566],\n",
    "'Henkjan Huisman': [34754023],\n",
    "'Colin Jacobs': [2895994],\n",
    "'Peter Koopmans': [34726383],\n",
    "'Jeroen van der Laak': [145441238, 145388932],\n",
    "'Geert Litjens': [145959882],\n",
    "'James Meakin': [4960344],\n",
    "'Keelin Murphy': [35730362],\n",
    "'Ajay Patel': [2109170880, 2116215861],\n",
    "'Cornelia Schaefer-Prokop': [1419819133, 1445069528, 1400632685],\n",
    "'Matthieu Rutten': [2074975080, 2156546],\n",
    "'Jos Thannhauser': [5752941],\n",
    "\"Bram Platel\" : [1798137], \n",
    "\"Nico Karssemeijer\" : [1745574], \n",
    "\"Clarisa Sanchez\" : [144085811, 32187701], \n",
    "\"Nikolas Lessman\" : [2913408], \n",
    "\"Jonas Teuwen\" : [32649341, 119024451], \n",
    "\"Rashindra Manniesing\" : [2657081]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d95c791e-7ebb-489d-8e58-981b93864d7c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "staff_year_dict = {\n",
    "'Bram van Ginneken':  {'start' : 1996, 'end': 9999},\n",
    "'Francesco Ciompi':  {'start' : 2013, 'end': 9999},\n",
    "'Alessa Hering':  {'start' : 2018, 'end': 9999},\n",
    "'Henkjan Huisman':  {'start' : 1992, 'end': 9999},\n",
    "'Colin Jacobs':  {'start' : 2010, 'end': 9999},\n",
    "'Peter Koopmans':  {'start' : 2022, 'end': 9999},\n",
    "'Jeroen van der Laak':  {'start' : 1991, 'end': 9999},\n",
    "'Geert Litjens':  {'start' : 2016, 'end': 9999},\n",
    "'James Meakin':  {'start' : 2017, 'end': 9999},\n",
    "'Keelin Murphy':  {'start' : 2018, 'end': 9999},\n",
    "'Ajay Patel':  {'start' : 2015, 'end': 9999},\n",
    "'Cornelia Schaefer-Prokop':  {'start' : 2010, 'end': 9999},\n",
    "'Matthieu Rutten':  {'start' : 2019, 'end': 9999},\n",
    "'Jos Thannhauser': {'start' : 2022, 'end': 9999},\n",
    "\"Bram Platel\" : {'start' : 2010,  'end' : 2019},\n",
    "\"Nico Karssemeijer\" : {'start' : 1989, 'end' : 2022}, \n",
    "\"Clarisa Sanchez\" : {'start' : 2008, 'end' : 2021}, \n",
    "\"Nikolas Lessman\" : {'start' : 2019, 'end' : 2022}, \n",
    "\"Jonas Teuwen\" : {'start' : 2017, 'end' : 2020}, \n",
    "\"Rashindra Manniesing\" : {'start' : 2010, 'end' : 2021}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65bf3ce0-346c-4a4c-a210-57397fcc29d9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_new_ssids():\n",
    "    staff_dict = {key: {'ids': staff_id_dict[key], 'years': staff_year_dict[key]} for key in staff_id_dict}\n",
    "    all_staff_id_ss_data = []\n",
    "\n",
    "    # get data for staff memb|er\n",
    "    for idx, (staff_name, values) in enumerate(staff_dict.items()):\n",
    "        staff_ids = values['ids']\n",
    "        staff_start = values['years']['start']\n",
    "        staff_end = values['years']['end']\n",
    "        print(f'[{idx+1}/{len(staff_dict.items())}]: {staff_name}')\n",
    "        for staff_id in staff_ids:\n",
    "            print('\\t\\t', staff_id)\n",
    "            staff_id_ss_data = []\n",
    "            # get semantic scolar data\n",
    "            url=f'https://api.semanticscholar.org/graph/v1/author/{staff_id}/papers?fields=year,title,authors,externalIds,citationCount&limit=500'\n",
    "            r = requests.get(url)\n",
    "            ss_staff_data = r.json()['data']\n",
    "\n",
    "            # loop over semantic scolar data entries\n",
    "            for ss_staff_entry in ss_staff_data:\n",
    "                ss_id = None\n",
    "                ss_title = None\n",
    "                ss_doi = None\n",
    "                ss_citations = None\n",
    "                ss_year = None\n",
    "\n",
    "                if 'paperId' in ss_staff_entry:\n",
    "                    ss_id = ss_staff_entry['paperId']\n",
    "                if 'title' in ss_staff_entry:\n",
    "                    ss_title = ss_staff_entry['title']\n",
    "                if 'DOI' in ss_staff_entry['externalIds']:\n",
    "                    ss_doi = ss_staff_entry['externalIds']['DOI']\n",
    "                if 'citationCount' in ss_staff_entry:\n",
    "                    ss_citations = ss_staff_entry['citationCount']\n",
    "                if 'year' in ss_staff_entry:\n",
    "                    ss_year = ss_staff_entry['year']\n",
    "\n",
    "                if ss_year != None:\n",
    "                    if not staff_start <= ss_year <= staff_end:\n",
    "                    # probably doesnt belong to DIAG, still captured via another staff member if also in the same paper\n",
    "                        continue\n",
    "\n",
    "                staff_id_ss_data.append([staff_id, staff_name, staff_start, staff_end, ss_year, ss_id, ss_title, ss_doi, ss_citations])\n",
    "            all_staff_id_ss_data.extend(staff_id_ss_data)    \n",
    "    ss_columns = ['staff_id', 'staff_name', 'staff_from', 'staff_till', 'ss_year', 'ss_id', 'title', 'doi', 'ss_citations']\n",
    "    df_all_staff_id_ss_data = pd.DataFrame(all_staff_id_ss_data, columns=ss_columns)\n",
    "    print('DONE')\n",
    "    return df_all_staff_id_ss_data, df_all_staff_id_ss_data['ss_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a3e2624-4f3e-4e4e-a58b-7e11b8a74902",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "url=f'https://api.semanticscholar.org/graph/v1/author/{143613202}/papers?fields=year,title,authors,externalIds,citationCount&limit=500'\n",
    "r = requests.get(url)\n",
    "ss_staff_data = r.json()['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e45e1142-5055-4d00-a355-30c613ce4b68",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def return_current_ssids(bib_file):\n",
    "    ss_ids=[]\n",
    "    for entry in bib_file:\n",
    "        if entry.type == 'string':\n",
    "            continue\n",
    "        if 'ss_id' in entry.fields:\n",
    "            ss_ids.append(entry.fields['ss_id'].translate(str.maketrans('', '', string.punctuation)))\n",
    "    return ss_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "265d82d3-0044-4656-9db7-0f0fea996f8f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/20]: Bram van Ginneken\n",
      "\t\t 8038506\n",
      "\t\t 123637526\n",
      "[2/20]: Francesco Ciompi\n",
      "\t\t 143613202\n",
      "[3/20]: Alessa Hering\n",
      "\t\t 153744566\n",
      "[4/20]: Henkjan Huisman\n",
      "\t\t 34754023\n",
      "[5/20]: Colin Jacobs\n",
      "\t\t 2895994\n",
      "[6/20]: Peter Koopmans\n",
      "\t\t 34726383\n",
      "[7/20]: Jeroen van der Laak\n",
      "\t\t 145441238\n",
      "\t\t 145388932\n",
      "[8/20]: Geert Litjens\n",
      "\t\t 145959882\n",
      "[9/20]: James Meakin\n",
      "\t\t 4960344\n",
      "[10/20]: Keelin Murphy\n",
      "\t\t 35730362\n",
      "[11/20]: Ajay Patel\n",
      "\t\t 2109170880\n",
      "\t\t 2116215861\n",
      "[12/20]: Cornelia Schaefer-Prokop\n",
      "\t\t 1419819133\n",
      "\t\t 1445069528\n",
      "\t\t 1400632685\n",
      "[13/20]: Matthieu Rutten\n",
      "\t\t 2074975080\n",
      "\t\t 2156546\n",
      "[14/20]: Jos Thannhauser\n",
      "\t\t 5752941\n",
      "[15/20]: Bram Platel\n",
      "\t\t 1798137\n",
      "[16/20]: Nico Karssemeijer\n",
      "\t\t 1745574\n",
      "[17/20]: Clarisa Sanchez\n",
      "\t\t 144085811\n",
      "\t\t 32187701\n",
      "[18/20]: Nikolas Lessman\n",
      "\t\t 2913408\n",
      "[19/20]: Jonas Teuwen\n",
      "\t\t 32649341\n",
      "\t\t 119024451\n",
      "[20/20]: Rashindra Manniesing\n",
      "\t\t 2657081\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "df, new_ss_ids = find_new_ssids()\n",
    "current_ss_ids=return_current_ssids(diag_bib_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of current ss_ids in diag_bib: 917\n",
      "Number of new ss_ids: 2200\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of current ss_ids in diag_bib: {len(current_ss_ids)}\")\n",
    "print(f\"Number of new ss_ids: {len(new_ss_ids)}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ss_ids not in the diag_bib but not in found by our staff member search"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "{'0257287f6628466cb01815358a9955962faf43af',\n '057100455efca559a6d38d31ed35cf56bdefc958',\n '0ab99aa04e3a8340a7552355fb547374a5604b24',\n '1a3c9f430cf163a3c2decdc9f04dae285739ace6',\n '3d01a44659fce1fb0134b6d8baabbee72583d3fe',\n '6493a6974ae6cb8e4188894fb9e2b5a6107fe424',\n '7cbf61f2d7b1fae068e3b815ebcb09e09555cd50',\n '9ca57befc51aee0d4bf6f19e951a776e4d1c9d82',\n 'efeaeef3e03c7e488095f3a38809d82b5f1766ac'}"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(current_ss_ids) - set(new_ss_ids)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "fe59f791-ab7f-4c26-abeb-5fab71a324e0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "There are 1631 unique semantic scholar ids found. The current bib file has 915 unique semantic scholar ids.\n",
    "The intersection is 910 = that means that there are 5 semantic scholar ids in the current bib that are not found from the new search. Why is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e960d6a7-9748-4bcc-b8ad-ba3956738399",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of newly found items: 721\n"
     ]
    }
   ],
   "source": [
    "found_items=set(new_ss_ids)-set(current_ss_ids)\n",
    "print(f\"Number of newly found items: {len(found_items)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a696eff4-3681-4091-b085-b6acd40c176a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_items = df[df['ss_id'].isin(found_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec181bcd-589c-4028-b21d-6a258adeea9a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_items = new_items[new_items['ss_year']>=2015]\n",
    "new_items = new_items.loc[new_items['doi'].notna()]\n",
    "new_items = new_items.drop_duplicates(subset='doi', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "25ebb975-51c5-4880-8ace-7ae59200a4aa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      staff_id            staff_name  staff_from  staff_till  ss_year  \\\n2      8038506     Bram van Ginneken        1996        9999   2023.0   \n3      8038506     Bram van Ginneken        1996        9999   2023.0   \n4      8038506     Bram van Ginneken        1996        9999   2023.0   \n5      8038506     Bram van Ginneken        1996        9999   2023.0   \n7      8038506     Bram van Ginneken        1996        9999   2023.0   \n...        ...                   ...         ...         ...      ...   \n2137   2657081  Rashindra Manniesing        2010        2021   2021.0   \n2139   2657081  Rashindra Manniesing        2010        2021   2021.0   \n2140   2657081  Rashindra Manniesing        2010        2021   2021.0   \n2141   2657081  Rashindra Manniesing        2010        2021   2021.0   \n2178   2657081  Rashindra Manniesing        2010        2021   2015.0   \n\n                                         ss_id  \\\n2     3c7c167e0619911a29ce6082372100fbbc5ca7af   \n3     4bcd672218ecec70473c84f6f1cc52c64031f3e5   \n4     7981606bf8110ec6cc64baa22d694096f7862939   \n5     9ddb2f47695191553a3623ac33eddeb9c7e416cd   \n7     be95c8bbd8a4297d620b1c2644cf2a898603e355   \n...                                        ...   \n2137  4202f56b0e22eedd6921d9b26519bc72f89cf4fd   \n2139  571285fab9ced6a4d0bf3abd5f886d9a64e1790c   \n2140  92a2cb9804d3599cc1e8e81c512d0203c6d10da7   \n2141  c859bd469080b82dc14db62e78d65ef5b5ffa686   \n2178  88b86ad75e10c7dac7b70edbd05ed494d699ffb0   \n\n                                                  title  \\\n2     Emphysema subtyping on thoracic computed tomog...   \n3     Continual learning strategies for cancer-indep...   \n4     AIROGS: Artificial Intelligence for RObust Gla...   \n5     The STOIC2021 COVID-19 AI challenge: applying ...   \n7     Kidney abnormality segmentation in thorax-abdo...   \n...                                                 ...   \n2137  Correction to: Incorporating radiomics into cl...   \n2139  Traumatic Cerebral Microbleeds in the Subacute...   \n2140  The radiological interpretation of possible mi...   \n2141  Incorporating radiomics into clinical trials: ...   \n2178          4D-CTA in Neurovascular Disease: A Review   \n\n                              doi  ss_citations  \n2      10.1038/s41598-023-40116-6             0  \n3     10.1016/j.media.2023.102755             3  \n4       10.48550/arXiv.2302.01738             4  \n5       10.48550/arXiv.2306.10484             1  \n7       10.48550/arXiv.2309.03383             0  \n...                           ...           ...  \n2137   10.1007/s00330-021-07721-3             4  \n2139           10.3174/ajnr.A7028             2  \n2140   10.1007/s00234-021-02839-z             2  \n2141   10.1007/s00330-020-07598-8            44  \n2178           10.3174/ajnr.A4162            75  \n\n[313 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>staff_id</th>\n      <th>staff_name</th>\n      <th>staff_from</th>\n      <th>staff_till</th>\n      <th>ss_year</th>\n      <th>ss_id</th>\n      <th>title</th>\n      <th>doi</th>\n      <th>ss_citations</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>8038506</td>\n      <td>Bram van Ginneken</td>\n      <td>1996</td>\n      <td>9999</td>\n      <td>2023.0</td>\n      <td>3c7c167e0619911a29ce6082372100fbbc5ca7af</td>\n      <td>Emphysema subtyping on thoracic computed tomog...</td>\n      <td>10.1038/s41598-023-40116-6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8038506</td>\n      <td>Bram van Ginneken</td>\n      <td>1996</td>\n      <td>9999</td>\n      <td>2023.0</td>\n      <td>4bcd672218ecec70473c84f6f1cc52c64031f3e5</td>\n      <td>Continual learning strategies for cancer-indep...</td>\n      <td>10.1016/j.media.2023.102755</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8038506</td>\n      <td>Bram van Ginneken</td>\n      <td>1996</td>\n      <td>9999</td>\n      <td>2023.0</td>\n      <td>7981606bf8110ec6cc64baa22d694096f7862939</td>\n      <td>AIROGS: Artificial Intelligence for RObust Gla...</td>\n      <td>10.48550/arXiv.2302.01738</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>8038506</td>\n      <td>Bram van Ginneken</td>\n      <td>1996</td>\n      <td>9999</td>\n      <td>2023.0</td>\n      <td>9ddb2f47695191553a3623ac33eddeb9c7e416cd</td>\n      <td>The STOIC2021 COVID-19 AI challenge: applying ...</td>\n      <td>10.48550/arXiv.2306.10484</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8038506</td>\n      <td>Bram van Ginneken</td>\n      <td>1996</td>\n      <td>9999</td>\n      <td>2023.0</td>\n      <td>be95c8bbd8a4297d620b1c2644cf2a898603e355</td>\n      <td>Kidney abnormality segmentation in thorax-abdo...</td>\n      <td>10.48550/arXiv.2309.03383</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2137</th>\n      <td>2657081</td>\n      <td>Rashindra Manniesing</td>\n      <td>2010</td>\n      <td>2021</td>\n      <td>2021.0</td>\n      <td>4202f56b0e22eedd6921d9b26519bc72f89cf4fd</td>\n      <td>Correction to: Incorporating radiomics into cl...</td>\n      <td>10.1007/s00330-021-07721-3</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2139</th>\n      <td>2657081</td>\n      <td>Rashindra Manniesing</td>\n      <td>2010</td>\n      <td>2021</td>\n      <td>2021.0</td>\n      <td>571285fab9ced6a4d0bf3abd5f886d9a64e1790c</td>\n      <td>Traumatic Cerebral Microbleeds in the Subacute...</td>\n      <td>10.3174/ajnr.A7028</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2140</th>\n      <td>2657081</td>\n      <td>Rashindra Manniesing</td>\n      <td>2010</td>\n      <td>2021</td>\n      <td>2021.0</td>\n      <td>92a2cb9804d3599cc1e8e81c512d0203c6d10da7</td>\n      <td>The radiological interpretation of possible mi...</td>\n      <td>10.1007/s00234-021-02839-z</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2141</th>\n      <td>2657081</td>\n      <td>Rashindra Manniesing</td>\n      <td>2010</td>\n      <td>2021</td>\n      <td>2021.0</td>\n      <td>c859bd469080b82dc14db62e78d65ef5b5ffa686</td>\n      <td>Incorporating radiomics into clinical trials: ...</td>\n      <td>10.1007/s00330-020-07598-8</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>2178</th>\n      <td>2657081</td>\n      <td>Rashindra Manniesing</td>\n      <td>2010</td>\n      <td>2021</td>\n      <td>2015.0</td>\n      <td>88b86ad75e10c7dac7b70edbd05ed494d699ffb0</td>\n      <td>4D-CTA in Neurovascular Disease: A Review</td>\n      <td>10.3174/ajnr.A4162</td>\n      <td>75</td>\n    </tr>\n  </tbody>\n</table>\n<p>313 rows Ã— 9 columns</p>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "497c8199-733f-4367-91f9-09b1b883e515",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dois = new_items['doi'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "238b3ae8-d9a8-4965-9d7c-1e46e9b2dcd4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ss_ids = new_items['ss_id'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8124c44a-e6d7-4b9c-b115-db369f0d70cc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Here: remove blacklist items**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483a8a65-052b-4bd5-bc73-299154def17f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Check dois: the first one refers to this publication https://www.semanticscholar.org/paper/Continual-learning-strategies-for-detection-of-node-B%C3%A1ndi-Balkenhol/4bcd672218ecec70473c84f6f1cc52c64031f3e5, it's already in diag.bib and should have a ss_id associated (it seems to be a one-to-one match). Why is it detected as a new item?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f795693d-183f-451b-b179-cf34d36464a6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting semanticscholar\n",
      "  Downloading semanticscholar-0.5.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\drepeeters\\.conda\\envs\\amara\\lib\\site-packages (from semanticscholar) (2.28.1)\n",
      "Collecting tenacity\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\drepeeters\\.conda\\envs\\amara\\lib\\site-packages (from requests->semanticscholar) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\drepeeters\\.conda\\envs\\amara\\lib\\site-packages (from requests->semanticscholar) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\drepeeters\\.conda\\envs\\amara\\lib\\site-packages (from requests->semanticscholar) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\drepeeters\\.conda\\envs\\amara\\lib\\site-packages (from requests->semanticscholar) (1.26.13)\n",
      "Installing collected packages: tenacity, semanticscholar\n",
      "Successfully installed semanticscholar-0.5.0 tenacity-8.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip3 install semanticscholar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee3356ec-945b-44dd-b556-d92fb1ff26dd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Code to get citations from semantic scholar. If there are multiple ss_ids, we should get the number of citations for each of them and sum the two (or more?) values. \n",
    "def get_citations(ss_id):\n",
    "    from semanticscholar import SemanticScholar\n",
    "    sch = SemanticScholar()\n",
    "    paper = sch.get_paper(ss_id)\n",
    "    return len(paper['citations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c8c1d406-7ff3-4b66-9fac-86827fff2b39",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Read the diag.bib file\n",
    "cwd = os.getcwd()\n",
    "parent_directory = os.path.abspath(os.path.join(cwd, \"..\"))\n",
    "diag_bib_path = os.path.join(parent_directory, 'diag.bib')\n",
    "\n",
    "with open(diag_bib_path, encoding=\"utf8\") as bibtex_file:\n",
    "    diag_bib = bibtex_file.read()\n",
    "\n",
    "for i, el in enumerate(dois): #Make sure to only use unique dois\n",
    "    citations = 0\n",
    "    if isinstance(ss_ids[i], list):\n",
    "        for ss_id in ss_ids[i]:\n",
    "            citations += get_citations(ss_id)\n",
    "    else:\n",
    "        citations = get_citations(ss_ids[i])\n",
    "    # Update Dre's code and add an extra argument for citations so that it uses the correct number when creating the bib item? \n",
    "    reader = GetBiblatex(doi=el, diag_bib=diag_bib, num_citations=citations)\n",
    "    bibtext = reader.get_bib_text()\n",
    "    # Code to add item to diag.bib ?\n",
    "    if bibtext != 'empty':\n",
    "        diag_bib = diag_bib + bibtext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}